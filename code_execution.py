# -*- coding: utf-8 -*-
"""Code_Execution.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Code_Execution.ipynb

##### Copyright 2024 Google LLC.
"""

# @title Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""# Code Execution in the Gemini API

<table align="left">
  <td>
    <a target="_blank" href="https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Code_Execution.ipynb"><img src="https://github.com/google-gemini/cookbook/blob/ce76bbe63554b4fceeba6bf6c2ef4b264d3d2da9/images/colab_logo_32px.png?raw=1" />Run in Google Colab</a>
  </td>
</table>

The Gemini API [code execution](https://ai.google.dev/gemini-api/docs/code-execution) feature enables the model to generate and run Python code based on plain-text instructions that you give it. It can learn iteratively from the results until it arrives at a final output.

This notebook is a walk through of how to use this feature.

### Set up
"""

import google.generativeai as genai
genai.__version__

"""To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see the [Authentication](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb) quickstart for an example."""

from google.colab import userdata
genai.configure(api_key=userdata.get('AIzaSyCVQjh2ouWOTTKA-n2Ml-smD6Ufw_aOiRI'))

"""Tweak CSS for display in Colab"""

from IPython.display import HTML, Markdown

def set_css_in_cell_output(unused):
  display(HTML("""<style>
div.output_markdown {
  font-size: 16px
}

div.output_markdown pre code {
  color: #222222;
}

div.output_markdown pre:nth-of-type(even) {
  background: #CCCCCC;
  margin: 16px;
  padding: 16px;
}

div.output_markdown pre:nth-of-type(odd) {
  background: #BBBBEE;
  margin: 16px;
  padding: 16px;
}
</style>"""))

get_ipython().events.register('pre_run_cell', set_css_in_cell_output)

"""## Pass `"code_execution"` as a `tool`

When initiating the model, pass `"code_execution"` as a `tool` to tell the model that it is allowed (but not forced) to generate and run code.
"""

model = genai.GenerativeModel(model_name='gemini-1.5-flash', tools="code_execution")

"""## Call `generate_content`"""

result = model.generate_content("What is the sum of the first 50 prime numbers?"
                                "Generate and run code for the calculation, and make sure you get all 50.")

"""The model returns a list of parts including `text`, `executable_code`, and `execution_result` parts."""

[
    list(type(p).to_dict(p))
    for p in result.candidates[0].content.parts
]

for part in result.candidates[0].content.parts:
  print(part)
  print()

"""The `.text` property formats the parts into Markdown compatible text:"""

print(result.text)

"""In a notebook you can display the Markdown:"""

from IPython.display import Markdown
Markdown(result.text)

"""Note: you can also set the `tools` argument on the call to `generate_content`:"""

model2 = genai.GenerativeModel(model_name='gemini-1.5-flash')

response = model2.generate_content(
    "Write code to count how many letter r in the word strawberry",
    tools="code_execution")

Markdown(response.text)

# """## Chat

# It works the same when using a `chat`:
# """

# chat = model.start_chat()

# """This time, you're going to ask the model to use a [Bogo-sort](https://en.wikipedia.org/wiki/Bogosort) algorithm to sort a list of numbers."""

# response = chat.send_message("Can you run some code to bogo-sort this list of numbers?: [2,34,1,65,4]")
# Markdown(response.text)

# response = chat.send_message("Modify the code to count the number of iterations. How many iterations does it take?")
# Markdown(response.text)

# """Try running the previous cell multiple times and you'll see a different number of iterations, indicating that the Gemini API indeed ran the code and obtained different results due to the nature of the algorithm.

# ## Multimedia

# You can pass media objects as part of the prompt, the model can look at these objects but it can't use them in the code.
# """

# ! curl -o montey_hall.png https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Monty_open_door.svg/640px-Monty_open_door.svg.png

# from PIL import Image
# montey_hall_image = Image.open("montey_hall.png")
# montey_hall_image

# prompt="""
# Run a simulation of the Monty Hall Problem with 1,000 trials.


# Here's how this works as a reminder. In the Monty Hall Problem, you're on a game
# show with three doors. Behind one is a car, and behind the others are goats. You
# pick a door. The host, who knows what's behind the doors, opens a different door
# to reveal a goat. Should you switch to the remaining unopened door?


# The answer has always been a little difficult for me to understand when people
# solve it with math - so please run a simulation with Python to show me what the
# best strategy is.


# Thank you!
# """
# result = model.generate_content([montey_hall_image, prompt])
# Markdown(result.text)

# """## Streaming

# Streaming is compatible with code execution. Just note that successive parts of the same type (`text`, `executable_code` or `execution_result`) are meant to be joined together:
# """

# result = model.generate_content([montey_hall_image, prompt], stream=True)
# for chunk in result:
#   print(chunk.candidates[0].content.parts[0])
#   print('----------------------------------------')

# """The result object automatically joins the parts, as you iterate over them:"""

# for part in result.candidates[0].content.parts:
#   print(part)
#   print('----------------------------------------')

# print(result.text)

"""## Next Steps
### Useful API references:

Check the [Code execution documentation](https://ai.google.dev/gemini-api/docs/code-execution) for more details about the feature and in particular, the [recommendations](https://ai.google.dev/gemini-api/docs/code-execution?lang=python#code-execution-vs-function-calling) regarding when to use it instead of [function calling](https://ai.google.dev/gemini-api/docs/function-calling).

### Continue your discovery of the Gemini API

Learn how to control how the Gemini API can call your own functions using the [function calling](../quickstarts/Function_calling.ipynb) feature, or discover how to control the model output in [JSON](../quickstarts/JSON_mode.ipynb) or using an [Enum](../quickstarts/Enum.ipynb).
"""